# ğŸ“Š Amazon Search Query Performance Analyzer

Ein intelligentes Tool zur Analyse von Amazon Search Query Performance Reports mit AI-gestÃ¼tzter Kategorisierung und visuellen Dashboards.

## ğŸš€ Features

### ğŸ”¹ Smart Ingestion Engine
- **Drag & Drop**: Sofortige Verarbeitung von Amazon SQP Reports (.csv/.xlsx)
- **Batch Processing**: Mehrere Wochen/Monate gleichzeitig hochladen fÃ¼r historische Trends
- **Privacy First**: Alle Datenverarbeitung erfolgt lokal in deiner Browser-Session

### ğŸ”¹ AI-Powered Categorization
- **GPT-5.1 Thinking**: Nutzt die neueste GPT-5.1 Thinking Technologie fÃ¼r tiefgreifende Analyse und prÃ¤zise Kategorisierung
- **Auto-Grouping**: Die KI gruppiert automatisch tausende rohe Search Terms in logische Produktkategorien
- **Niche Discovery**: Trennt sofort "Generic" Traffic von "Branded" Traffic ohne manuelles Tagging
- **Reasoning Effort**: Konfigurierbare Reasoning-Tiefe (high empfohlen) fÃ¼r optimale Ergebnisse

### ğŸ”¹ Visual Intelligence Dashboard
- **Opportunity Matrix**: Bubble Chart visualisiert High Volume vs. Low Market Share Nischen
- **Market Trend Analysis**: Dual-Axis Charts vergleichen Market Volume vs. Sales Velocity Ã¼ber Zeit
- **Share of Voice Tracking**: Ãœberwache deinen Brand Share (Impression % vs. Sales %) auf Kategorie-Ebene

### ğŸ”¹ Deep Dive Analytics
- **Search Term Granularity**: Drill-Down von Kategorie-Ebene zu einzelnen Search Terms
- **Performance Metrics**: Sofortige Ansicht von Total Volume, Market Sales und deinem spezifischen Share fÃ¼r jede Query

## ğŸ“‹ Voraussetzungen

- Python 3.8 oder hÃ¶her
- OpenAI API Key mit Zugriff auf GPT-5.1 (fÃ¼r AI-Kategorisierung)

## ğŸ› ï¸ Installation

1. **Repository klonen oder Dateien herunterladen**

2. **Dependencies installieren:**
```bash
pip install -r requirements.txt
```

3. **Umgebungsvariablen einrichten:**

   **Option A: FÃ¼r lokale Entwicklung** - Erstelle eine `.env` Datei im Hauptverzeichnis:
```env
OPENAI_API_KEY=dein-api-key-hier
OPENAI_MODEL=gpt-5.1
REASONING_EFFORT=high
```

   **Option B: FÃ¼r Streamlit Cloud/GitHub Deployment** - Setze die Secrets direkt in Streamlit:
   - Gehe zu deiner Streamlit App â†’ Settings â†’ Secrets
   - FÃ¼ge folgende Secrets hinzu:
   ```toml
   OPENAI_API_KEY = "dein-api-key-hier"
   OPENAI_MODEL = "gpt-5.1"
   REASONING_EFFORT = "high"
   ```
   
   **REASONING_EFFORT Optionen** (nur fÃ¼r GPT-5.1):
   - `none`: Kein zusÃ¤tzliches Reasoning
   - `minimal`: Minimales Reasoning
   - `low`: Geringes Reasoning
   - `medium`: Mittleres Reasoning
   - `high`: Tiefes Reasoning (empfohlen fÃ¼r komplexe Kategorisierungen)
   
   **Hinweis:** Die App unterstÃ¼tzt beide Methoden automatisch. FÃ¼r Deployment auf Streamlit Cloud reicht es, die Secrets in Streamlit zu setzen - keine `.env` Datei nÃ¶tig!

4. **App starten:**
```bash
streamlit run app.py
```

Die App Ã¶ffnet sich automatisch in deinem Browser unter `http://localhost:8501`

## ğŸ“– Verwendung

### 1. Data Ingestion
- Navigiere zur "ğŸ“¤ Data Ingestion" Seite
- Lade eine oder mehrere CSV/XLSX Dateien hoch
- Die Daten werden automatisch bereinigt und standardisiert

### 2. AI Categorization
- Gehe zur "ğŸ¤– AI Categorization" Seite
- Klicke auf "ğŸš€ Starte AI-Kategorisierung"
- Die KI kategorisiert alle Search Terms automatisch

### 3. Dashboard
- Auf der "ğŸ“Š Dashboard" Seite findest du:
  - Opportunity Matrix fÃ¼r Revenue-Opportunities
  - Trend-Analysen
  - Share of Voice Tracking
  - Performance Heatmaps

### 4. Deep Dive Analytics
- Die "ğŸ” Deep Dive Analytics" Seite ermÃ¶glicht:
  - Filterung nach Kategorie, Search Term, Impressions
  - Detaillierte Performance-Metriken pro Query
  - Export der gefilterten Daten

## ğŸš€ Deployment auf Streamlit Cloud

1. **GitHub Repository erstellen** und Code pushen
2. **Streamlit Cloud** Ã¶ffnen: https://share.streamlit.io
3. **New App** erstellen und Repository verbinden
4. **Secrets setzen**:
   - Gehe zu Settings â†’ Secrets
   - FÃ¼ge folgende Secrets hinzu:
   ```toml
   OPENAI_API_KEY = "dein-api-key-hier"
   OPENAI_MODEL = "gpt-5.1"
   REASONING_EFFORT = "high"
   ```
5. **Deploy** - Die App wird automatisch deployed!

**Wichtig:** Die Secrets werden sicher in Streamlit Cloud gespeichert und sind nicht im Code sichtbar.

## ğŸ” Privacy & Security

- **Lokale Verarbeitung**: Alle Daten werden nur in deiner Browser-Session verarbeitet
- **Keine Speicherung**: Keine Daten werden auf dem Server gespeichert
- **API Calls**: Nur fÃ¼r AI-Kategorisierung werden Search Terms an die OpenAI API gesendet
- **Sichere Secrets**: API Keys werden Ã¼ber Streamlit Secrets verwaltet (nicht im Code)

## ğŸ”® ZukÃ¼nftige Features

- [ ] Supabase Datenbank-Integration fÃ¼r persistente Speicherung
- [ ] Multi-User Support mit Authentifizierung
- [ ] Automatische Report-Generierung
- [ ] Email-Benachrichtigungen fÃ¼r neue Opportunities
- [ ] Historische Trend-Vergleiche Ã¼ber mehrere Perioden

## ğŸ“ Projektstruktur

```
Search-Query-Performance-Analyzer/
â”œâ”€â”€ app.py                 # Haupt-Streamlit-App
â”œâ”€â”€ config.py              # Konfigurationsdatei
â”œâ”€â”€ requirements.txt        # Python Dependencies
â”œâ”€â”€ .env                   # Umgebungsvariablen (nicht im Repo)
â”œâ”€â”€ README.md              # Diese Datei
â””â”€â”€ utils/
    â”œâ”€â”€ data_processor.py  # Datenverarbeitungs-Engine
    â”œâ”€â”€ ai_categorizer.py  # AI-Kategorisierungs-Engine
    â””â”€â”€ visualizations.py  # Visualisierungs-Engine
```

## ğŸ› Troubleshooting

### OpenAI API Fehler
- Stelle sicher, dass dein API Key in der `.env` Datei korrekt gesetzt ist
- ÃœberprÃ¼fe dein API-Kontingent bei OpenAI

### Datei-Upload Probleme
- Stelle sicher, dass die Datei ein gÃ¼ltiges Amazon SQP Report Format hat
- ÃœberprÃ¼fe, ob die Datei nicht zu groÃŸ ist (empfohlen: < 50MB)

### Performance Probleme
- Bei groÃŸen DatensÃ¤tzen: Reduziere die Batch Size fÃ¼r AI-Kategorisierung
- Verwende Filter auf der Deep Dive Seite fÃ¼r bessere Performance

## ğŸ“„ Lizenz

Dieses Projekt ist fÃ¼r den internen Unternehmensgebrauch bestimmt.

## ğŸ¤ Support

Bei Fragen oder Problemen, kontaktiere das Entwicklungsteam.

---

**Erstellt mit â¤ï¸ fÃ¼r bessere Amazon Performance Analyse**

